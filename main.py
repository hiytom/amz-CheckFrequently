import csv
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from search import search_products
from scraper import get_product_details

# é…ç½®
SEARCH_QUERY = "vintage apron"
CSV_FILE = "amazon_asins.csv"
OUTPUT_FILE = "amazon_listings.csv"
MAX_THREADS = 5  # æ§åˆ¶æœ€å¤§çº¿ç¨‹æ•°ï¼Œé˜²æ­¢è¢«å° IP

# 1ï¸âƒ£ è·å– ASIN åˆ—è¡¨
asins = search_products(SEARCH_QUERY, CSV_FILE)

if not asins:
    print("âŒ æ²¡æœ‰æ‰¾åˆ° ASINï¼Œé€€å‡ºç¨‹åºï¼")
    exit()

# 2ï¸âƒ£ å¤„ç†çˆ¬å–å•†å“è¯¦æƒ…ï¼ˆä½¿ç”¨å¤šçº¿ç¨‹ï¼‰


def process_asin(asin):
    product_data = get_product_details(asin)
    if product_data:
        return product_data
    return None


# 3ï¸âƒ£ å­˜å…¥ CSV
with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as file:
    writer = csv.writer(file)
    writer.writerow(["ASIN", "Title", "Price", "URL",
                    "Frequently Returned"])  # CSV è¡¨å¤´

    # ä½¿ç”¨å¤šçº¿ç¨‹çˆ¬å–
    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
        future_to_asin = {executor.submit(
            process_asin, asin): asin for asin in asins}

        for future in as_completed(future_to_asin):
            product_data = future.result()
            if product_data:
                writer.writerow([product_data["asin"], product_data["title"], product_data["price"],
                                 product_data["url"], product_data["frequently_returned"]])
                print(f"âœ… å·²å­˜å…¥ CSV: {product_data['title']}")

            # é˜²æ­¢è¢« Amazon å° IPï¼Œçº¿ç¨‹é—´éšæœºå»¶è¿Ÿ
            time.sleep(random.uniform(3, 8))

print(f"\nğŸ‰ æ‰€æœ‰å•†å“ä¿¡æ¯å·²ä¿å­˜åˆ° `{OUTPUT_FILE}`ï¼")
