import csv
import time
import random
from multiprocessing import Pool
from search import search_products
from scraper import get_product_details
from playwright.sync_api import sync_playwright
import json

# è¯»å–é…ç½®æ–‡ä»¶
with open("config.json", "r") as f:
    config = json.load(f)

SEARCH_QUERY = config["search_query"]
CSV_FILE = config["csv_file"]
OUTPUT_FILE = config["output_file"]
MAX_PROCESSES = config["max_processes"]
MAX_PAGES = config["max_pages"]
COOKIES_FILE = config["cookies_file"]


def process_asin(asin):
    """è®©æ¯ä¸ª ASIN ç‹¬ç«‹è¿è¡Œ Playwright"""
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()

        # **åŠ è½½ Amazon ç™»å½• Cookies**
        try:
            with open("amazon_cookies.json", "r") as f:
                cookies = json.load(f)
                context.add_cookies(cookies)
        except:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° Cookiesï¼Œå¯èƒ½éœ€è¦å…ˆè¿è¡Œ `login.py` æ‰‹åŠ¨ç™»å½•")
            return None

        page = context.new_page()
        product_data = get_product_details(asin, page)

        page.close()
        browser.close()
        return product_data


if __name__ == "__main__":
    # 1ï¸âƒ£ è·å– ASIN åˆ—è¡¨
    asins = search_products(SEARCH_QUERY, CSV_FILE)

    if not asins:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° ASINï¼Œé€€å‡ºç¨‹åºï¼")
        exit()

    # 2ï¸âƒ£ **ä½¿ç”¨ `multiprocessing.Pool()` è¿›è¡Œå¹¶è¡Œçˆ¬å–**
    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ASIN", "Title", "Price", "URL",
                        "Frequently Returned"])  # **CSV è¡¨å¤´**

        with Pool(processes=MAX_PROCESSES) as pool:
            results = pool.map(process_asin, asins)  # **ç¡®ä¿åªä¼ é€’ ASIN**

            for product_data in results:
                if product_data:
                    writer.writerow([product_data["asin"], product_data["title"], product_data["price"],
                                    product_data["url"], product_data["frequently_returned"]])
                    print(f"âœ… å·²å­˜å…¥ CSV: {product_data['title']}")

    print(f"\nğŸ‰ æ‰€æœ‰å•†å“ä¿¡æ¯å·²ä¿å­˜åˆ° `{OUTPUT_FILE}`ï¼")
